{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook sets up a SFINCS model for the area of interest and the period of the flood event. In this example, the October 2023 storm surge in the area Fsichland-Darss-Zingst in on the German Baltic Coast. \n",
    "1. Standard SFINCS model.\n",
    "2. SFINCS model with added dikes\n",
    "3. SFINCS model with dikes and breaches in dikes.   \n",
    "\n",
    "#TO DO: Add wind (water level timeseries at observation point 2 does not match well yet, might miss wind set up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydromt_sfincs import SfincsModel\n",
    "from hydromt.config import configread\n",
    "from hydromt.log import setuplog\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from hydromt_sfincs import utils\n",
    "import xarray as xr\n",
    "from shapely.geometry import Point\n",
    "import requests, zipfile, io\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USER INPUT\n",
    "\n",
    "Set the model directory.\n",
    "Set start and end times \n",
    "Select the data sources. Here we use local data for bathymetry and topography, which are specified in the data.yml file. \n",
    "Water level forcings are received from a local tide gauge. Provide coordinates in the model's coordinate reference system and the download url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-09 09:37:52,396 - hydromt - log - INFO - HydroMT version: 0.10.1\n"
     ]
    }
   ],
   "source": [
    "# Model directory\n",
    "main_dir = Path(r\"p:\\11209308-floodadapt-trinidad\\InterTwin\")\n",
    "model_dir = \"model\"\n",
    "run_name = \"model_20m_final\"      \n",
    "\n",
    "# Start and end times\n",
    "tstart= \"20231015 070000\"\n",
    "tstop= \"20231023 000000\"\n",
    "\n",
    "# model resolution\n",
    "res = 20\n",
    "\n",
    "mask_file = main_dir.joinpath(\"Geodaten\\mask_25833.geojson\")\n",
    "\n",
    "# water levels\n",
    "wl_csv = main_dir.joinpath(\"Wasserstaende\\pegelonline-barhft-W-20231015-20231023.csv\")\n",
    "# offset of tide gauge from local datum\n",
    "waterlevel_offset = -498\n",
    "\n",
    "# INitial water level\n",
    "inifile = main_dir.joinpath(\"Geodaten\\zsini_regridded_20m_final.tif\")\n",
    "\n",
    "logger = setuplog()\n",
    "# opt = configread(os.path.join(main_dir,\"fdz_base.yml\"))\n",
    "\n",
    "# Bathymetry and topography data in data.yml\n",
    "data_libs=main_dir.joinpath(\"TopoBathy\\data.yml\")\n",
    "datasets_dep = [{\"elevtn\": \"MVtopo_masked\", \"zmin\": 0.01},{\"elevtn\": \"ELC_INSPIRE\"},{\"elevtn\": \"merit_hydro\"}]\n",
    "\n",
    "# Water level boundary point coordinates (Barhoeft)\n",
    "x = [372368.1]\n",
    "y = [6033653.6]\n",
    "\n",
    "# wind url\n",
    "wind_url = \"https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/wind/historical/stundenwerte_FF_00298_19810101_20231231_hist.zip\"\n",
    "wind_dir = main_dir.joinpath(\"Wind\")\n",
    "\n",
    "# Observation points for model validation\n",
    "d = {'Station': [\"Barhoeft\",\"Barth\",\"Althagen\"], \n",
    "     'geometry': [\n",
    "         Point(371100.0, 6034300.0), \n",
    "         Point(352691.1, 6027443.5),\n",
    "         Point(332296.2, 6027473.9),\n",
    "         ]}\n",
    "\n",
    "dike_file = main_dir.joinpath(\"Geodaten\\all_dikes.gpkg\")\n",
    "\n",
    "breach_locations = {'Location': [\"1\",\"2\"], \n",
    "     'geometry': [\n",
    "         Point(342608.0, 6030840.0), \n",
    "         Point(344915.1, 6031933.0),\n",
    "         ]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate SFINCS model and set\n",
    "- Timing\n",
    "- Resolution\n",
    "- Mask\n",
    "- Depth\n",
    "- Roughness\n",
    "- Initial water level. This is important in this use case because some if the land is below zero. Hence we prepared an initial water level map with zero in the water bodies and -1 over land.\n",
    "\n",
    "Slow when using the p-drive. Alternatively, copy all folders to local drive and change main_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-09 09:21:34,344 - hydromt - data_catalog - INFO - Parsing data catalog from p:\\11209308-floodadapt-trinidad\\InterTwin\\TopoBathy\\data.yml\n",
      "2025-04-09 09:21:35,009 - hydromt - model_api - INFO - Initializing sfincs model from hydromt_sfincs (v1.1.0).\n",
      "2025-04-09 09:21:35,034 - hydromt - geodataframe - INFO - Reading  vector data from p:\\11209308-floodadapt-trinidad\\InterTwin\\Geodaten\\mask_25833.geojson\n",
      "2025-04-09 09:21:35,098 - hydromt - rasterdataset - INFO - Reading MVtopo_masked raster data from p:\\11209308-floodadapt-trinidad\\InterTwin\\TopoBathy\\mv_masked_clipped.tif\n",
      "2025-04-09 09:21:35,188 - hydromt - rasterdataset - INFO - Reading ELC_INSPIRE raster data from p:\\11209308-floodadapt-trinidad\\InterTwin\\TopoBathy\\Baltic_Sea_Bathy.tif\n",
      "2025-04-09 09:21:35,304 - hydromt - rasterdataset - INFO - Reading merit_hydro raster data from p:\\wflow_global\\hydromt\\topography\\merit_hydro\\*.vrt\n",
      "2025-04-09 09:29:01,645 - hydromt - sfincs - WARNING - Interpolate elevation at 20816 cells\n",
      "2025-04-09 09:29:03,452 - hydromt - geodataframe - INFO - Reading  vector data from p:\\11209308-floodadapt-trinidad\\InterTwin\\Geodaten\\mask_25833.geojson\n",
      "2025-04-09 09:29:03,819 - hydromt - regulargrid - INFO - 0 gaps outside valid elevation range < 10.0 km2.\n",
      "2025-04-09 09:29:03,884 - hydromt - sfincs - INFO - Derive region geometry based on active cells.\n",
      "2025-04-09 09:29:04,025 - hydromt - model_api - WARNING - Replacing geom: region\n"
     ]
    }
   ],
   "source": [
    "# Make model\n",
    "sf = SfincsModel(data_libs=data_libs,root=os.path.join(main_dir,run_name), mode='w+', logger=logger)\n",
    "\n",
    "sf.setup_config(\n",
    "    tref= tstart,\n",
    "    tstart= tstart,\n",
    "    tstop= tstop,\n",
    "    dtout= 10400.0,\n",
    "    dthisout= 600.0,\n",
    "    dtmaxout= 259200.0,\n",
    "    zsini=-1.0,\n",
    "    tspinup=86400,\n",
    "    \n",
    ")\n",
    "sf.setup_grid_from_region(\n",
    "    region = {'geom': mask_file},\n",
    "    res = res,\n",
    "    rotated = False,\n",
    "    crs = 25833,\n",
    ")\n",
    "# sf.setup_dep(**opt['setup_dep'])\n",
    "# sf.setup_subgrid(**opt['setup_dep'])\n",
    "\n",
    "# Add depth information to modelgrid based on these chosen datasets\n",
    "dep = sf.setup_dep(datasets_dep=datasets_dep)\n",
    "\n",
    "sf.setup_mask_active(\n",
    "    include_mask= mask_file,\n",
    "    zmax= -50.0\n",
    ")\n",
    "sf.setup_mask_bounds(\n",
    "    btype=\"waterlevel\",\n",
    "    zmax= 0\n",
    ")\n",
    "\n",
    "\n",
    "# dep = sf.setup_subgrid(\n",
    "#     datasets_dep=datasets_dep,\n",
    "#     # manning_land=0.04,\n",
    "#     # manning_sea=manning_sea, \n",
    "#     # rgh_lev_land=0.0,\n",
    "#     write_dep_tif=True,\n",
    "#     write_man_tif=True,\n",
    "#     nr_subgrid_pixels=4,\n",
    "#     )\n",
    "\n",
    "# set up roughness \n",
    "sf.setup_manning_roughness(\n",
    "    manning_land=0.04,\n",
    "    manning_sea=0.02,\n",
    "    rgh_lev_land=0,  # the minimum elevation of the land\n",
    ")\n",
    "\n",
    "# set initial water level to zero, except over land set it to -1\n",
    "ini_ds = xr.open_dataset(inifile, engine=\"rasterio\")\n",
    "ini_ds[\"zsini\"] = ini_ds[\"band_data\"]\n",
    "ini_ds = ini_ds.drop([\"band_data\"])\n",
    "sf.set_states(data=ini_ds[\"zsini\"])\n",
    "sf.set_config(\"inifile\",\"sfincs.ini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'joinpath'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m z \u001b[38;5;241m=\u001b[39m zipfile\u001b[38;5;241m.\u001b[39mZipFile(io\u001b[38;5;241m.\u001b[39mBytesIO(response\u001b[38;5;241m.\u001b[39mcontent))\n\u001b[0;32m      4\u001b[0m z\u001b[38;5;241m.\u001b[39mextractall(wind_dir)\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[43mwind_dir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoinpath\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprodukt_ff_stunde_19810101_20231231_00298.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      6\u001b[0m df\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# dict = json.loads(response.content)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# dict\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# sf.config\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'joinpath'"
     ]
    }
   ],
   "source": [
    "\n",
    "# download and add wind\n",
    "response = requests.get(wind_url)\n",
    "z = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "z.extractall(wind_dir)\n",
    "df = pd.read_csv(wind_dir.joinpath(\"produkt_ff_stunde_19810101_20231231_00298.txt\"))\n",
    "df\n",
    "# dict = json.loads(response.content)\n",
    "# dict\n",
    "\n",
    "# sf.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add boundary point and water level at the boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up water level boundary point (Barhoeft)\n",
    "# add to Geopandas dataframe as needed by HydroMT\n",
    "pnts = gpd.points_from_xy(x, y)\n",
    "index = [1]  # NOTE that the index should start at one\n",
    "bnd = gpd.GeoDataFrame(index=index, geometry=pnts, crs=sf.crs)\n",
    "\n",
    "display(bnd)\n",
    "\n",
    "# add waterlevel forcing\n",
    "# we use measured timeseries\n",
    "df = pd.read_csv(wl_csv, header=0,delimiter=\";\")\n",
    "df=df.rename(columns={\"timestamp\":\"time\", \"value\":1})\n",
    "df[1]=pd.to_numeric(df[1])\n",
    "\n",
    "time = pd.to_datetime(df[\"time\"])\n",
    "\n",
    "# and the actual water levels, in this case for input location 1 a water level rising from 0 to 2 meters and back to 0:\n",
    "bzs = ((df[1]+waterlevel_offset)/100).to_list()\n",
    "\n",
    "bzspd = pd.DataFrame(index=time, columns=index, data=bzs)\n",
    "display(bzspd)\n",
    "\n",
    "# Actually add it to the SFINCS model class:\n",
    "sf.setup_waterlevel_forcing(timeseries=bzspd, locations=bnd, buffer=1000)\n",
    "\n",
    "# NOTE: the waterlevel forcing data is now stored in the sf.forcing dictionary\n",
    "sf.forcing.keys()\n",
    "sf.plot_forcing(fn_out=\"forcing.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add observation points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup observation points \n",
    "gdf = gpd.GeoDataFrame(d, crs=\"EPSG:25833\")\n",
    "display(gdf)\n",
    "\n",
    "sf.setup_observation_points(\n",
    "    locations=gdf, merge=False\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results\n",
    "sf.write()\n",
    "sf.plot_basemap()\n",
    "plt.savefig(os.path.join(main_dir,run_name,'basemap.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model with dikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dikes\n",
    "# HydroMT function: get geodataframe from dike_file\n",
    "gdf_floodwall = sf.data_catalog.get_geodataframe(\n",
    "    dike_file, geom=sf.region, crs=sf.crs\n",
    ")\n",
    "\n",
    "# Add floodwall attributes to geodataframe\n",
    "if (gdf_floodwall.geometry.type == \"MultiLineString\").any():\n",
    "    gdf_floodwall = gdf_floodwall.explode()\n",
    "\n",
    "# par1 is the overflow coefficient for weirs\n",
    "gdf_floodwall[\"par1\"] = 0.6\n",
    "\n",
    "# HydroMT function: create floodwall\n",
    "sf.setup_structures(structures=gdf_floodwall, stype=\"weir\", merge=False)\n",
    "\n",
    "run_name_dikes = run_name+\"_dikes\"      \n",
    "\n",
    "sf.set_root(root=os.path.join(main_dir,run_name_dikes), mode=\"w+\")\n",
    "sf.write()\n",
    "sf.plot_basemap()\n",
    "plt.savefig(os.path.join(main_dir,run_name_dikes,'basemap.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove line segments near breach from dike line features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find dike breaches\n",
    "s = gpd.GeoSeries(gdf_floodwall.geometry)\n",
    "breach_ids = s.sindex.nearest(breach_locations[\"geometry\"])\n",
    "gdf_floodwall_breached=gdf_floodwall.drop(index=breach_ids[1])\n",
    "\n",
    "# par1 is the overflow coefficient for weirs\n",
    "gdf_floodwall_breached[\"par1\"] = 0.6\n",
    "\n",
    "# HydroMT function: create floodwall\n",
    "sf.setup_structures(structures=gdf_floodwall_breached, stype=\"weir\", merge=False)\n",
    "\n",
    "run_name_dikes = run_name+\"_dikes_withbreaches\"      \n",
    "\n",
    "sf.set_root(root=os.path.join(main_dir,run_name_dikes), mode=\"w+\")\n",
    "sf.write()\n",
    "sf.plot_basemap()\n",
    "plt.savefig(os.path.join(main_dir,run_name_dikes,'basemap.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative: not remove but lower dikes near breaches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find dike breaches\n",
    "s = gpd.GeoSeries(gdf_floodwall.geometry)\n",
    "breach_ids = s.sindex.nearest(breach_locations[\"geometry\"])\n",
    "gdf_floodwall_overtopped=gdf_floodwall.copy()\n",
    "\n",
    "gdf_floodwall_overtopped[\"z\"].loc[breach_ids[1]] = 0.8  \n",
    "\n",
    "# par1 is the overflow coefficient for weirs\n",
    "gdf_floodwall_overtopped[\"par1\"] = 0.6\n",
    "\n",
    "\n",
    "# HydroMT function: create floodwall\n",
    "sf.setup_structures(structures=gdf_floodwall_overtopped, stype=\"weir\", merge=False)\n",
    "\n",
    "run_name_dikes = run_name+\"_dikes_overtopping\"      \n",
    "\n",
    "sf.set_root(root=os.path.join(main_dir,run_name_dikes), mode=\"w+\")\n",
    "sf.write()\n",
    "sf.plot_basemap()\n",
    "plt.savefig(os.path.join(main_dir,run_name_dikes,'basemap.png'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfincs_gfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
