{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create FloodAdapt site.toml\n",
    "\n",
    "This notebook creates a baseline site.toml configuration file for FloodAdapt, based in part on the SFINCS and Delft-FIAT models set up with the previous notebooks.\n",
    "\n",
    "Missing entries that are not optional in the SiteModel class will throw errors when trying to read in the site.toml. Optional entries that are missing will be set to None during read-in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "#import hydromt\n",
    "from hydromt_sfincs import SfincsModel\n",
    "from hydromt_fiat.fiat import FiatModel\n",
    "from pprint import pprint\n",
    "import shutil\n",
    "from os import makedirs\n",
    "import tomli_w\n",
    "\n",
    "from flood_adapt.object_model.site import Site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths and read models\n",
    "First set the paths to the overall FloodAdapt folder, and the SFINCS and FIAT models used, and finally read those in.\n",
    "\n",
    "Also here we set the path to where we want to save the site.toml file to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Humber'\n",
    "# model_path = Path('c:/Repositories/DT-flood/FloodAdapt_database') / model_name\n",
    "model_path = Path(\"/mnt/c/Repositories/DT-flood/FloodAdapt_database\") / model_name\n",
    "\n",
    "sf_root = model_path / Path(\"static/templates/overland\")\n",
    "fiat_root = model_path / Path(\"static/templates/fiat\")\n",
    "\n",
    "site_fn = model_path / \"static\" / \"site\" / \"site.toml\"\n",
    "if not site_fn.parent.exists():\n",
    "    makedirs(site_fn.parent)\n",
    "\n",
    "sf = SfincsModel(root=sf_root,mode=\"r\")\n",
    "sf.read()\n",
    "\n",
    "fiatmodel = FiatModel(root=fiat_root,mode=\"r\")\n",
    "fiatmodel.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empty dictionary to store all the site.toml settings in before writing it to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base naming\n",
    "Set some base info about the model, name, description. Latitude and longitude we take from the SFINCS domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dict = {\n",
    "    \"name\": model_name,\n",
    "    \"description\": \"Humber Delta, UK\",\n",
    "    \"lat\": round(sf.region.to_crs(4326).unary_union.centroid.y,2),\n",
    "    \"lon\": round(sf.region.to_crs(4326).unary_union.centroid.x,2)\n",
    "}\n",
    "\n",
    "site_dict.update(base_dict)\n",
    "pprint(site_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SFINCS settings\n",
    "\n",
    "Here we specify some SFINCS settings/properties:\n",
    "- `csname`: Name of the SFINCS CRS\n",
    "- `cstype`: CRS type, one of 'projected','spherical'\n",
    "- `version`: SFINCS release version used\n",
    "- `offshore_model`: Name of the offshore model, empty string for no model\n",
    "- `overland_model`: Name of overland model\n",
    "- `datum_offshore_model`: Reference DEM datum for offshore model\n",
    "- `datum_overland_model`: Reference DEM datum for overland model\n",
    "- `diff_datum_offshore_overland`: height difference between offshore and overland reference (a UnitfulValue dict)\n",
    "- `tidal_components`: Specification of tides used (a filepath)\n",
    "- `ambient_air_pressure`: average air pressure, taken from SFINCS forcing\n",
    "- `floodmap_no_data_value`: ID for missing data in floodmap\n",
    "- `floodmap_units`: unit of waterlevel/depth in floodmap (fully written out, FloodAdapt cannot parse abbreviations)\n",
    "\n",
    "None of the sfincs entry and the above options/entries into the site.toml are optional. A value has to be entered even when the option is not used (e.g. an empty string for offshore_model when no offshore_model is used)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# floodmap entries can be automated once sfincs has run once, but to run sfincs in floodadapt context site.toml needs to exist first\n",
    "\n",
    "sfincs_dict = {\n",
    "    \"csname\": sf.crs.name,\n",
    "    \"cstype\": sf.crs.type_name[:9].lower(), # this only works cause projected and spherical (only allowed inputs) have same length coincidentally\n",
    "    \"version\": \"SFINCS_v2.0.1_tag_exe\", #\"sfincs20_AlpeDHuez_release\",\n",
    "    \"offshore_model\": \"\",\n",
    "    \"overland_model\": Path(sf.root).stem,\n",
    "    \"ambient_air_pressure\": round(sf.forcing[\"press_2d\"].values.mean()),\n",
    "    \"floodmap_units\": \"meters\",\n",
    "    \"save_simulation\": False,\n",
    "}\n",
    "\n",
    "site_dict.update({\"sfincs\": sfincs_dict})\n",
    "pprint(site_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Water level\n",
    "\n",
    "Here we specify how the different data used for topography, bathymetry relate to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_dict = {\n",
    "    \"reference\": {\n",
    "        \"name\": \"MSL\",\n",
    "        \"height\": {\n",
    "            \"value\": 0,\n",
    "            \"units\": \"meters\"\n",
    "        }\n",
    "    },\n",
    "    \"localdatum\": {\n",
    "        \"name\": \"EGM2008\",\n",
    "        \"height\": {\n",
    "            \"value\": 0,\n",
    "            \"units\": \"meters\"\n",
    "        }\n",
    "    },\n",
    "    \"msl\": {\n",
    "        \"name\": \"MSL\",\n",
    "        \"height\": {\n",
    "            \"value\": 0,\n",
    "            \"units\": \"meters\"\n",
    "        }\n",
    "    },\n",
    "    }\n",
    "\n",
    "site_dict.update({\"water_level\": wl_dict})\n",
    "pprint(site_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIAT settings\n",
    "\n",
    "Here we specify some FIAT setting/properties, and create the static/bfe folder if one doesn't exist yet:\n",
    "- `exposure_crs`: CRS of the exposure file, taken from the FIAT model\n",
    "- `building_foortprints`: Specification of building footprints in FIAT domain (filepath to shapefile, OPTIONAL)\n",
    "- `non_building_names`: ID for non-building objects (OPTIONAL)\n",
    "- `aggregation`: different aggregation levels to use (dict containing name, filepath, and relevant field name)\n",
    "- `bfe`: Base Flood Elevation height reference (dict containing geom, field name, and (optional) table, US only)\n",
    "\n",
    "The building_footprints, non_building_names, and bfe.table are optional, meaning they will be set to None when the site.toml is read in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (model_path / \"static\" / \"bfe\").exists():\n",
    "    shutil.copytree((model_path.parents[1] / \"data\" / \"base_flood_elevation\"),(model_path / \"static\" / \"bfe\"))\n",
    "\n",
    "if not (fiat_root/\"aggregation_areas\").exists():\n",
    "    makedirs(fiat_root/\"aggregation_areas\")\n",
    "\n",
    "# agg_area_folder = Path('c:/Repositories/DT-flood/Data/aggregation_zones')\n",
    "agg_area_folder = Path(\"/mnt/c/Repositories/DT-flood/Data/aggregation_zones\")\n",
    "aggregation_area_fn = agg_area_folder/\"gadm41_GBR_3.shp\"\n",
    "target_file = fiat_root / \"aggregation_areas\" / aggregation_area_fn.name\n",
    "if not target_file.exists():\n",
    "    target_file.touch()\n",
    "shutil.copy(aggregation_area_fn,target_file)\n",
    "\n",
    "fiat_dict = {\n",
    "    \"exposure_crs\": fiatmodel.exposure.crs,\n",
    "    \"floodmap_type\": \"water_level\", # This depends on sfincs is subgrid or not? Automate from sfincs results?\n",
    "    # \"building_footprints\": \"\",\n",
    "    # \"non_building_names\": [],\n",
    "    \"aggregation\": [{\n",
    "        \"name\": \"gadm_level3\",\n",
    "        \"file\": \"../templates/fiat/aggregation_areas/\"+target_file.name,\n",
    "        \"field_name\": \"NAME_3\",\n",
    "    }],\n",
    "    \"bfe\": {\n",
    "        \"geom\": \"\",\n",
    "        \"field_name\": \"\",\n",
    "        # \"table\": \"\"\n",
    "        },\n",
    "    \"non_building_names\": [\"\"],\n",
    "}\n",
    "\n",
    "site_dict.update({\"fiat\": fiat_dict})\n",
    "pprint(site_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyclone Tracking Database\n",
    "\n",
    "File path to the cyclone database. This is not optional, use empty string when no cyclones are modeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (model_path / \"static\" / \"cyclone_track_database\").exists():\n",
    "    shutil.copytree((model_path.parents[1] / \"data\" / \"cyclone_database\"),(model_path / \"static\" / \"cyclone_track_database\"))\n",
    "\n",
    "cdt_dict = {\n",
    "    \"file\": \"\"\n",
    "}\n",
    "\n",
    "site_dict.update({\"cyclone_track_database\": cdt_dict})\n",
    "pprint(site_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sea level rise\n",
    "\n",
    "Details of the included sea level rise:\n",
    "- `relative_to_year`: which year is used as a reference point.\n",
    "- `vertical_offset`: sea level increase or decrease relative to specified year (UnitfulLength, a dict)\n",
    "\n",
    "The /static/slr folder is created when one doesn't exist yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (model_path / \"static\" / \"slr\").exists():\n",
    "    shutil.copytree((model_path.parents[1] / \"data\" / \"sea_level_projections\"),(model_path / \"static\" / \"slr\"))\n",
    "\n",
    "slr_dict = {\n",
    "    \"relative_to_year\": 2020,\n",
    "    \"vertical_offset\": {\n",
    "        \"value\": 0.2,\n",
    "        \"units\": \"meters\"\n",
    "    }\n",
    "}\n",
    "\n",
    "site_dict.update({\"slr\": slr_dict})\n",
    "pprint(site_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUI\n",
    "\n",
    "Some settings for the GUI units. This is not optional. (Double check that nans for tide amplitude actually works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gui_dict = {\n",
    "    \"tide_harmonic_amplitude\": {\n",
    "        \"value\": 0,\n",
    "        \"units\": \"meters\"\n",
    "    },\n",
    "    \"default_length_units\": \"meters\",\n",
    "    \"default_distance_units\": \"meters\",\n",
    "    \"default_area_units\": \"m2\",\n",
    "    \"default_volume_units\": \"m3\",\n",
    "    \"default_velocity_units\": \"m/s\",\n",
    "    \"default_discharge_units\": \"m3/s\",\n",
    "    \"default_intensity_units\": \"mm/hr\",\n",
    "    \"default_direction_units\": \"deg N\",\n",
    "    \"default_cumulative_units\": \"meters\",\n",
    "    \"mapbox_layers\": {\n",
    "        \"flood_map_depth_min\": 0,\n",
    "        \"flood_map_zbmax\": 0,\n",
    "        \"flood_map_bins\": [],\n",
    "        \"flood_map_colors\": [],\n",
    "        \"aggregation_dmg_bins\": [],\n",
    "        \"aggregation_dmg_colors\": [],\n",
    "        \"footprints_dmg_bins\": [],\n",
    "        \"footprints_dmg_colors\": [],\n",
    "        \"benefits_bins\": [],\n",
    "        \"benefits_colors\": [],\n",
    "    },\n",
    "    \"visualization_layers\": {\n",
    "        \"default_bin_number\": 0,\n",
    "        \"default_colors\": [],\n",
    "        \"layer_names\": [],\n",
    "        \"layer_long_names\": [],\n",
    "        \"layer_paths\": [],\n",
    "        \"field_names\": [],\n",
    "    }\n",
    "}\n",
    "site_dict.update({\"gui\": gui_dict})\n",
    "pprint(site_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk\n",
    "\n",
    "Set risk settings/properties (not optional, also not for event_mode = single_event):\n",
    "- `return_periods`: How often the event reoccurs\n",
    "- `flooding_threshold`: How high a water level counts as a flood event (UnitfulValue, a dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_dict = {\n",
    "    \"return_periods\": [1, 2, 5, 10, 25, 50, 100],\n",
    "    \"flooding_threshold\": {\n",
    "        \"value\": 0.15,\n",
    "        \"units\": \"meters\"\n",
    "    }\n",
    "}\n",
    "\n",
    "site_dict.update({\"risk\": risk_dict})\n",
    "pprint(site_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEM\n",
    "\n",
    "The high resolution DEM used for downscaling the floodmap. Here taken from the sfincs subgrid dem.\n",
    "\n",
    "Unsure what the index file does, so double check that this is indeed the correct one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (model_path / \"static\" / \"dem\").exists():\n",
    "    makedirs(model_path / \"static\" / \"dem\")\n",
    "\n",
    "shutil.copy((model_path / \"static\" / \"templates\" / \"overland\" / \"subgrid\" / \"dep_subgrid.tif\"),\n",
    "            model_path / \"static\" / \"dem\" / (model_name+\"_subgrid.tif\"))\n",
    "# Not sure this is the right thing to do. Is this the needed index file and is this the correct location?\n",
    "shutil.copy((model_path / \"static\" / \"templates\" / \"overland\" / \"sfincs.ind\"),\n",
    "            model_path / \"static\" / \"dem\" / (model_name+\"_index.tif\"))\n",
    "\n",
    "# Site object cannot parse Path objects\n",
    "dem_dict = {\n",
    "    \"filename\": (model_path / \"static\" / \"dem\" / (model_name+\"_subgrid.tif\")).name,\n",
    "    \"indexfilename\": (model_path / \"static\" / \"dem\" / (model_name+\"_index.tif\")).name,\n",
    "    \"units\": \"meters\"\n",
    "}\n",
    "\n",
    "site_dict.update({\"dem\": dem_dict})\n",
    "pprint(site_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefits model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benefit_dict = {\n",
    "    \"current_year\": 2023, # Could get this from SFINCS sim times, maybe not right when running scenarios?\n",
    "    \"current_projection\": \"current\", # Creating this toml file in right location done in another notebook\n",
    "    \"baseline_strategy\": \"no_measures\", # Creating this toml file in right location done in another notebook\n",
    "    \"event_set\": \"test_set\", # Creating this toml file in right location done in another notebook\n",
    "}\n",
    "\n",
    "site_dict.update({\"benefits\": benefit_dict})\n",
    "pprint(site_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation Points\n",
    "Taken from SFINCS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_point_list = []\n",
    "\n",
    "for _, row in sf.geoms['obs'].to_crs(4326).iterrows():\n",
    "    point_dict = {\n",
    "        'name': row['name'],\n",
    "        'lat': row['geometry'].y,\n",
    "        'lon': row['geometry'].x,\n",
    "    }\n",
    "    obs_point_list.append(point_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_dict.update({\"obs_point\": obs_point_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## River\n",
    "River is (should be?) optional, but not specifying anything will create a None type when reading in site.toml, which doesn't play well with scenario.run(). The underlying problem is in event.add_dis_ts() where len(site_river) is used. So river should at least be an emtpy list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_dict.update({\"river\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save file\n",
    "\n",
    "Write the created site dictionary to site.toml at the specified location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(site_fn,\"wb\") as f:\n",
    "    tomli_w.dump(site_dict,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_load = Site.load_file(Path('n:/Deltabox/Postbox/Tromp, Willem/Database_env_fix/static/site/site.toml'))\n",
    "test_load = Site.load_file(site_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(test_load.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## River, SCS, Obs station (Optional)\n",
    "\n",
    "The below settings are optional, they are not strictly needed to run FloodAdapt. Uncomment, change the relevant settings you want to add, and save the site.toml file again if you want to include them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not (model_path / \"static\" / \"scs\").exists():\n",
    "#     shutil.copytree((model_path.parents[1] / \"data\" / \"rainfall_series\"),(model_path / \"static\" / \"scs\"))\n",
    "\n",
    "# site_dict.update({\"river\": []})\n",
    "# site_dict.update({\"scs\": {\n",
    "#     \"file\": \"\",\n",
    "#     \"type\": \"\"\n",
    "# }})\n",
    "\n",
    "# obs_dict = {\n",
    "#     \"name\": \"\",\n",
    "#     \"ID\": -9999,\n",
    "#     \"lat\": np.nan,\n",
    "#     \"lon\": np.nan,\n",
    "#     \"mhhw\": {\n",
    "#         \"value\": np.nan,\n",
    "#         \"units\": \"meters\"\n",
    "#     },\n",
    "#     \"mllw\": {\n",
    "#         \"value\": np.nan,\n",
    "#         \"units\": \"meters\"\n",
    "#     },\n",
    "#     \"localdatum\": {\n",
    "#         \"value\": np.nan,\n",
    "#         \"units\": \"meters\"\n",
    "#     },\n",
    "#     \"msl\": {\n",
    "#         \"value\": np.nan,\n",
    "#         \"units\": \"meters\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# site_dict.update({\"obs_station\":obs_dict})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
