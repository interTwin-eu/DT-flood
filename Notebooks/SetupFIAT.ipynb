{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Delft-FIAT model for the FloodAdapt backend\n",
    "\n",
    "This notebook demonstrates how to set up a Delft-FIAT model anywhere in the world ready to be used in FloodAdapt. As an example we will create a model for the city of Kingston upon Hull, UK, in the Humber delta. The relevant data will be taken from [OpenStreetMap (OSM)](https://www.openstreetmap.org) and the [global flood vulnerability datasets from JRC](https://publications.jrc.ec.europa.eu/repository/handle/JRC105688). Both the data sources and the region of interest (the model domain) can be changed according to the user's wishes.\n",
    "\n",
    "*Disclaimer: The outcomes of this model are not validated*\n",
    "\n",
    "## **Step 0**: Import required packages\n",
    "First we need to import the necessary python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from hydromt_fiat.workflows.exposure_vector import ExposureVector\n",
    "from hydromt_fiat.fiat import FiatModel\n",
    "from hydromt.log import setuplog\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "from xrspatial import zonal_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1:** List Input Names\n",
    "Here we list the input paths and names of some needed utilities:\n",
    "- `model_name`: This is the name for the overall FloodAdapt folder where everything will be stored. Named after region of interest (in this case)\n",
    "- `model_path`: The full path of the FloodAdapt model folder\n",
    "- `fiat_root`: Path to folder parsed by FloodAdapt where FIAT model is stored.\n",
    "- `fiat_logger_name`: Name for the FIAT logger\n",
    "- `region_fn`: Path to geojson file of the region of interest. Used when building FIAT domain\n",
    "- `data_catalog_fn`: Path to data_catalog yml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Humber'\n",
    "model_path = Path('/home/wotromp/InterTwin/FloodAdapt_database') / model_name\n",
    "\n",
    "fiat_root = model_path / Path('static/templates/fiat')\n",
    "\n",
    "fiat_logger_name = \"FIAT_logger\"\n",
    "\n",
    "region_fn = model_path / 'HumberDelta_large.geojson'\n",
    "\n",
    "data_catalog_fn = Path('/home/wotromp/InterTwin/Data/Humber/data_catalog.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2**: Initialize\n",
    "In this step we initialize HydroMT-FIAT with the `model_folder`, `data_catalog`, and `logger` that we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiat_logger = setuplog(fiat_logger_name, log_level=10)\n",
    "\n",
    "fiat = FiatModel(root=fiat_root, data_libs=[data_catalog_fn], mode='w+', logger=fiat_logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3a:** Configure model - Setup Region\n",
    "Build the model domain with the geojson file specified earlier. We also need to indicate the country and continent the model domain is in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = gpd.read_file(region_fn)\n",
    "\n",
    "continent = 'Europe'\n",
    "country = 'United Kingdom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3b:** Configure model - Configure input data\n",
    "\n",
    "Next, we need to specify properties of the various dataset. For the vulnerability and exposure data HydroMT-FIAT needs the names and unit of the datasets. The names should correspond to the names (keys) in the data catalog except from the OSM data, which is accessed with the [OSMnx Python package](https://geoffboeing.com/publications/osmnx-complex-street-networks/). Should you wish to use different data sources, *make sure to update the data catalog*. For the output data, we need to specify the output file names and where to store them. The parameter names below are parsed by the model builder, so they should not be changed.\n",
    "\n",
    "**Vulnerability**\n",
    "- `vulnerability_fn`: the source name of the vulnerability curve dataset as defined in the HydroMT-FIAT global data catalog. In this example, we use the JRC global damage curves.\n",
    "- `vulnerability_identifiers_and_linking_fn`: the source name of the *occupancy type-vulnerability curves* linking table as defined in the HydroMT-FIAT data catalog. In this example, we use the default table for linking the OSM land use classese to the JRC damage curves (i.e., the assets classified as residential links to the residential vulnerability curves of JRC).\n",
    "- `unit`: the unit of the vulnerability curves. The JRC curves are in meters.\n",
    "\n",
    "**Exposure**\n",
    "- `asset_locations`: the source name of the location and (optionally) geometry data of the assests for which damages will be calculated. In this example, the building footprints from OSM are used.\n",
    "- `occupancy_type`: the source name of the occupancy type data to classify the assets. In this example, the land use data from OSM is used.\n",
    "- `max_potential_damage`: the source name of the maximum potential damage values data. In this example, the JRC maximum damage values are used.\n",
    "- `ground_floor_height`: the height of the ground floor of all assets, in the same `unit`\n",
    "- `unit`: the unit of the exposure data\n",
    "\n",
    "**Output**\n",
    "- `output_dir`: the name of the output directory\n",
    "- `output_csv_name`: the name of the output CSV\n",
    "- `output_vector_name`: the name of the vector output file(s)\n",
    "\n",
    "*Note: The unit names are parsed by FloodAdapt. See FloodAdapt's UnitfulValue for correct formatting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setup vulnerability parameters ###\n",
    "vulnerability_fn = \"jrc_vulnerability_curves\"\n",
    "vulnerability_identifiers_and_linking_fn = \"jrc_vulnerability_curves_linking\"\n",
    "unit = \"meters\"\n",
    "\n",
    "### Setup exposure parameters ###\n",
    "asset_locations = \"OSM\"\n",
    "occupancy_type = \"OSM\"\n",
    "max_potential_damage = \"jrc_damage_values\"\n",
    "ground_floor_height = 0\n",
    "ground_floor_height_unit = \"meters\"\n",
    "damage_types = ['total']\n",
    "ground_elevation_file = model_path / 'static' / 'dem' / \"Humber_subgrid.tif\"\n",
    "\n",
    "### Setup output parameters ###\n",
    "output_dir = \"output\"\n",
    "output_csv_name = \"output.csv\"\n",
    "output_vector_name = \"spatial.gpkg\"\n",
    "\n",
    "### Setup Aggregation Zone parameters ###\n",
    "# agg_area_folder = Path('c:/Repositories/DT-flood/Data/aggregation_zones')\n",
    "# aggregation_area_fn = [agg_area_folder/\"gadm41_GBR_3.shp\"]\n",
    "aggregation_area_fn = fiat.data_catalog['gadm_level1'].path\n",
    "attribute_names = [\"NAME_1\"]\n",
    "label_names = [\"AdminZonesLevel1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = {\n",
    "    \"setup_output\": {\n",
    "        \"output_dir\": output_dir,\n",
    "        \"output_csv_name\": output_csv_name,\n",
    "        \"output_vector_name\": output_vector_name,\n",
    "    },\n",
    "    \"setup_vulnerability\": {\n",
    "        \"vulnerability_fn\": vulnerability_fn,\n",
    "        \"vulnerability_identifiers_and_linking_fn\": vulnerability_identifiers_and_linking_fn,\n",
    "        \"continent\": continent,\n",
    "        \"unit\": unit,\n",
    "    },\n",
    "    \"setup_exposure_buildings\": {\n",
    "        \"asset_locations\": asset_locations,\n",
    "        \"occupancy_type\": occupancy_type,\n",
    "        \"max_potential_damage\": max_potential_damage,\n",
    "        \"ground_floor_height\": ground_floor_height,\n",
    "        \"unit\": ground_floor_height_unit,\n",
    "        \"country\": country,\n",
    "        \"damage_types\": damage_types,\n",
    "        \"ground_elevation_file\": ground_elevation_file,\n",
    "    },\n",
    "    \"setup_aggregation_areas\": {\n",
    "        \"aggregation_area_fn\": aggregation_area_fn,\n",
    "        \"attribute_names\": attribute_names,\n",
    "        \"label_names\": label_names,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 4:** Build model\n",
    "\n",
    "In this step we build the Delft-FIAT model. Depending on the extent of the model it can take some time to download the building footprints and land use data from OSM. During the building of the model, log messages display what is happening.\n",
    "\n",
    "*Note that the model will not yet be written because of setting the write argument to False.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiat.build(region={\"geom\": region}, opt=configuration, write=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiat.set_geoms(region.dissolve(), 'region')\n",
    "fiat.region.set_crs(region.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 5**: Inspect model\n",
    "We now inspect the resulting exposure data and vulnerability curves that will be saved in the `fiat` instance.\n",
    "\n",
    "### Exposure data\n",
    "In the map below, the region and Secondary Object Type of the exposure objects are plotted. You can zoom in and see whether the data makes sense, perhaps using Google maps and/or streetview to validate the occupancy types.\n",
    "\n",
    "*Note: In Delft-FIAT, exposure is defined with object footprints, lines or centroids. In this example we are only using the buildings extracted from the OSM data. This means we are not going to look into, e.g., farmland, roads, etc. but that is possible with Delft-FIAT.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiat.exposure.get_full_gdf(fiat.exposure.exposure_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiat.region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the geodataframe with exposure data\n",
    "gdf = fiat.exposure.get_full_gdf(fiat.exposure.exposure_db)\n",
    "\n",
    "# Plot the region and the secondary object types of the exposure data\n",
    "m = region.explore(name='Region', style_kwds={'color': 'black', 'fill': False})\n",
    "m = gdf.explore(m=m, column='Secondary Object Type', name='Exposure types')\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 6:** Write model\n",
    "\n",
    "Finally, write the model in a folder structure appropriate for FloodAdapt. The right folders should be created automatically if our `model_path` and `fiat_root` are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiat.write()\n",
    "\n",
    "def tree(directory):\n",
    "    print(f\"+ {directory}\")\n",
    "    for path in sorted(directory.rglob('*')):\n",
    "        depth = len(path.relative_to(directory).parts)\n",
    "        spacer = \"  \" * depth\n",
    "        print(f\"{spacer}+ {path.name}\")\n",
    "\n",
    "\n",
    "tree(Path(fiat.root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 7:** Double check exposure csv\n",
    "\n",
    "The written exposure csv is probably missing the 'Ground Elevation' column, without which FIAT won't run. This column contains the average height of each building footprint. Here we calculate these numbers using xrspatial.zonal_stats. We will use the SFINCS subgrid as DEM.\n",
    "\n",
    "We do need to be carefull with the zonal_stats output. This generally contains less entries than the number of shapes, due to either duplicate shapes (the csv contains the same footprint multiple times with different asset types) or geometries being rasterized to the same pixels. The rasterize output will only contain the results of the last occurence. We use the fact that in either case the rasterization is the same to copy the appropriate results for the shapes that didn't get rasterized.\n",
    "\n",
    "*Note: hydromt also has a zonal_stats function but it's very slow*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_path = model_path / 'static' / 'templates' / 'overland' / 'subgrid' / 'dep_subgrid.tif'\n",
    "exposure_path = fiat_root / 'exposure' / 'exposure.csv'\n",
    "buildings_path = fiat_root / 'exposure' / 'buildings.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a GeoDataFrame of the exposure csv\n",
    "exposure = pd.read_csv(exposure_path)\n",
    "buildings = gpd.read_file(buildings_path)\n",
    "gdf = buildings.merge(exposure, on=\"Object ID\")\n",
    "# gdf = gpd.GeoDataFrame(exposure.drop(columns='geometry'), geometry=gpd.GeoSeries.from_wkt(exposure['geometry']),crs=\"EPSG:4326\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the DEM\n",
    "dem = rasterio.open(dem_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the exposure geometries to the dem crs\n",
    "gdf = gdf.to_crs(dem.crs.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of geometries plus a label for rasterize\n",
    "# The labels start at 1 since the label 0 is reserved for everything not in a geometry\n",
    "# The order of each tuple is (geometry,label)\n",
    "shapes = list(enumerate(gdf['geometry'].values))\n",
    "shapes = [(t[1],t[0]+1) for t in shapes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterized = rasterize(\n",
    "    shapes=shapes,\n",
    "    out_shape=dem.shape,\n",
    "    transform=dem.transform,\n",
    "    all_touched=True\n",
    ")\n",
    "# zonal_stats needs xarrays as input\n",
    "rasterized = xr.DataArray(rasterized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the zonal statistics\n",
    "zonal_out = zonal_stats(rasterized,xr.DataArray(dem.read(1)),\n",
    "                        stats_funcs=['mean'],\n",
    "                        nodata_values=np.nan)\n",
    "\n",
    "# The zero label is for pixels not in a geometry so we discard them\n",
    "zonal_out = zonal_out.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array storing the zonal means\n",
    "# Store the calculated means at index corresponding to their label\n",
    "zonal_means = np.full(len(shapes),np.nan)\n",
    "zonal_means[[zonal_out['zone'].values-1]] = zonal_out['mean'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Ground Elevation column and get rid of nans in the appropriate way\n",
    "exposure['Ground Elevation'] = zonal_means\n",
    "exposure['Ground Elevation'].bfill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "exposure_path.unlink()\n",
    "exposure.to_csv(exposure_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 8:** Manual aggregation zones\n",
    "\n",
    "Should the setup_aggregation_areas fail when building the model, comment `setup_aggregation_areas` in the `config` dict and run the below cells. This will manually configure the aggregation areas with the data specified in `aggregation_area_fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the exposure table and the aggregation zone file\n",
    "# exposure_gdf = fiat.exposure.get_full_gdf(fiat.exposure.exposure_db)\n",
    "exposure_path = fiat_root / 'exposure' / 'exposure.csv'\n",
    "buildings_path = fiat_root / 'exposure' / 'buildings.gpkg'\n",
    "\n",
    "exposure = pd.read_csv(exposure_path)\n",
    "buildings = gpd.read_file(buildings_path)\n",
    "\n",
    "exposure_gdf = buildings.merge(exposure, on=\"Object ID\")\n",
    "agg_zone_gdf = gpd.read_file(aggregation_area_fn[0], mask=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two\n",
    "exposure_gdf = gpd.sjoin(\n",
    "    exposure_gdf,\n",
    "    agg_zone_gdf[[\"geometry\", attribute_names[0]]],\n",
    "    op=\"intersects\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle duplicate Object IDs\n",
    "aggregated_gdf = exposure_gdf.groupby(\"Object ID\")[attribute_names[0]].agg(list).reset_index()\n",
    "\n",
    "exposure_gdf.drop_duplicates(subset=\"Object ID\", keep=\"first\", inplace=True)\n",
    "exposure_gdf.drop(columns=attribute_names[0], inplace=True)\n",
    "exposure_gdf = exposure_gdf.merge(aggregated_gdf, on=\"Object ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up by renaming and deleting appropriate columns\n",
    "\n",
    "def process_value(value):\n",
    "    if isinstance(value, list) and len(value) == 1:\n",
    "        return value[0]\n",
    "    elif isinstance(value, list) and len(value) > 1:\n",
    "        return \", \".join(value)\n",
    "    else:\n",
    "        return value\n",
    "    \n",
    "exposure_gdf[attribute_names[0]] = exposure_gdf[attribute_names[0]].apply(process_value)\n",
    "\n",
    "exposure_gdf.rename(columns={attribute_names[0]: f\"Aggregation Label: {label_names[0]}\"}, inplace=True)\n",
    "\n",
    "if \"index_right\" in exposure_gdf.columns:\n",
    "    del exposure_gdf[\"index_right\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save new exposure table\n",
    "exposure_path.unlink()\n",
    "exposure_gdf.to_csv(exposure_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
