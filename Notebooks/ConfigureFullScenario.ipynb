{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure a Scenario for FloodAdapt\n",
    "\n",
    "In this notebook we are going to setup a scenario for FloodAdapt to run. This includes a weather event, any adaptation measures and future projections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 0:** Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import tomli_w\n",
    "from flood_adapt.objects.measures.measures import MeasureType\n",
    "\n",
    "from DT_flood.utils.fa_scenario_utils import (\n",
    "    create_event,\n",
    "    create_measure,\n",
    "    create_projection,\n",
    "    get_database,\n",
    ")\n",
    "from DT_flood.utils.plot_utils import draw_database_map, list_agg_areas\n",
    "from DT_flood.utils.workflow_utils import (\n",
    "    create_workflow_config,\n",
    "    run_fa_scenario_workflow,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1:** Set paths to folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the FloodAdapt database for which we are configuring scenarios\n",
    "fa_database = Path(\"/home/wotromp/InterTwin/workflow_refactor/fa_database/Humber_new\")\n",
    "\n",
    "database = get_database(database_path=fa_database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2:** Configure the weather Event\n",
    "\n",
    "Here we will specify everything needed to setup an event. For now we will only consider scenarios which involve just a single event.\n",
    "\n",
    "To fully specify an event we will need the following:\n",
    "- A name for referencing\n",
    "- Start and end time and dates\n",
    "- Forcing data for the hazard models. Either paths to data files or keys for data catalogues. See HydroMT (SFINCS,WFlow) for naming conventions of data variables\n",
    "    - When using a single dataset for meteorological data this needs to contain precipitation, wind speeds, and pressure. Otherwise use individual data sources for each\n",
    "\n",
    "WFlow requires two sets of forcings, one for the warmup run, and one for the event run. See HydroMT WFlow `setup_precip_forcing` and `setup_temp_pet_forcing` which data variables should be included (conveniently ERA5 provides them all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of already existing events\n",
    "events_existing = database.get_events()\n",
    "print(events_existing['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of event\n",
    "event_name = 'test_event_rucio2'\n",
    "\n",
    "# Start and end times of the event\n",
    "start_time = '2013-12-04 00:00:00'\n",
    "end_time = '2013-12-10 00:00:00'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = create_event(database=database, name=event_name, start_time=start_time, end_time=end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3:** Configure projections\n",
    "\n",
    "Here we specify, where applicable, the projected future changes relevant to our scenario. These come in two flavors: physical projections and socio-economic changes. The former contains changes on the hazard side (sea level rise, land subsidence etc.) while the latter contains changes to the impact side (population growth, economic growth etc.).\\\n",
    "The supported projections are:\\\n",
    "\\\n",
    "**Physical Projections:**\n",
    "- Sea level rise\n",
    "- Land subsidence\n",
    "- Rainfall increase\n",
    "- Storm frequency increase\n",
    "\n",
    "**Socio-Economic Projections:**\n",
    "- Population growth\n",
    "- Economic growth\n",
    "- New developments:\n",
    "    - Newly developed area\n",
    "    - Elevation of newly developed area\n",
    "    - Population growth in newly developed area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of already existing projections\n",
    "proj_existing = database.get_projections()\n",
    "print(proj_existing['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of projection\n",
    "projection_name = 'slr_test'\n",
    "\n",
    "# Physical projections\n",
    "sea_level_rise = 1.5\n",
    "rainfall_increase = 0\n",
    "\n",
    "\n",
    "# Socio-Economic projections\n",
    "pop_growth = 0\n",
    "economic_growth = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = create_projection(database=database, name=projection_name, sea_level_rise=sea_level_rise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 4:** Configure Measures\n",
    "\n",
    "Here we configure all the measure we want to implement for this scenario. These come in either Impact or Hazard types, either reducing the vulnerability to a hazard, or dampen the hazard itself. In either case we need to specify in which area the measure acts by specifying a geojson file or in the case of Impact types an area name recognized by the aggregation area file. For the Impact type we also need to specify which building type to act on.\\\n",
    "The supported measures are:\\\n",
    "\\\n",
    "**Hazard Type:**\n",
    "- Floodwall\n",
    "- Pump\n",
    "- Water square\n",
    "- Green infrastructure\n",
    "- Water storage\n",
    "\n",
    "**Impact Type:**\n",
    "- Elevate properties\n",
    "- Floodproof properties\n",
    "- Buyout properties\n",
    "\n",
    "All the measures needed for the scenario are collected into a single strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some useful stuff\n",
    "\n",
    "print(\"Existing measures:\")\n",
    "meas_existing = database.get_measures()\n",
    "print(meas_existing['name'])\n",
    "\n",
    "print(\"Allowed measure types:\")\n",
    "print([e.value for e in MeasureType])\n",
    "\n",
    "print(\"Existing Aggreagation area types:\")\n",
    "print(list_agg_areas(database=database))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, selected_geom = draw_database_map(database, agg_area_name=\"AdminZonesLevel3\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_name = \"test_buyout_all\"\n",
    "measure_type = \"buyout_properties\"\n",
    "\n",
    "measure_value = 1.0\n",
    "property_type = \"commercial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure = create_measure(database=database, name=measure_name, measure_type=measure_type, value=measure_value, selection=selected_geom, property_type=property_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check measure set up worked (validation of measure selection type only happens when trying to fetch it from database)\n",
    "print(\"Existing measures:\")\n",
    "meas_existing = database.get_measures()\n",
    "print(meas_existing['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 4b:** Setup a strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 5:** Collect everything into a single Scenario\n",
    "\n",
    "Now that we have configured each individual element of a scenario (event, projection, measure) we can collect everything together into a single scenario definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = {\n",
    "    'name': \"test_rucio_scenario\",\n",
    "    'event': event_dict,\n",
    "    'projection': proj_dict,\n",
    "    'strategy': strategy,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to toml file. The _toplevel suffix indicated that this is a toml file also configuring non-FloodAdapt functionalities\n",
    "scenario_fn = fa_database / \"input\" / \"scenarios\" / scenario[\"name\"] / f\"{scenario['name']}_toplevel.toml\"\n",
    "\n",
    "if not scenario_fn.parent.exists():\n",
    "    scenario_fn.parent.mkdir(parents=True)\n",
    "\n",
    "with open(scenario_fn, 'wb+') as f:\n",
    "    tomli_w.dump(scenario, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 6:** Launch workflow\n",
    "\n",
    "With a complete definition of the scenario we can run the workflow. First we export the cwl config file based on the scenario settings we just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import tomli_w\n",
    "from DT_flood.utils.workflow_utils import create_workflow_config, run_fa_scenario_workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_fn = Path(\"/home/wotromp/InterTwin/workflow_refactor/fa_database/Humber_new\")\n",
    "scenario_name = \"test_rucio_scenario\"\n",
    "\n",
    "oscar_endpoint = 'https://oscar-ukri.intertwin.fedcloud.eu'\n",
    "oscar_token = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rucio.client\n",
    "\n",
    "\n",
    "client = rucio.client.Client()\n",
    "client.list_accounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_workflow_config(database_fn, scenario_name, oscar_endpoint=oscar_endpoint, oscar_token=oscar_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_fa_scenario_workflow(database_fn, scenario_name, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DT_flood.utils.fa_scenario_utils import init_scenario\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, scenario = init_scenario(database_path=database_fn, scenario_name=scenario_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.database.events.get(scenario[\"event\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.database.projections.get(\"empty_projection\").physical_projection.sea_level_rise.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_adpt = db.database.static.get_overland_sfincs_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_adpt._load_scenario_objects(\n",
    "    db.database.scenarios.get(scenario[\"name\"]),\n",
    "    db.database.events.get(scenario[\"event\"][\"name\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_adpt.set_timing(sf_adpt._event.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_adpt._model.get_model_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(vars(db.site))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiat_path = db.output_path/\"scenarios\"/\"test_scenario\"/\"Impacts\"/\"fiat_model\"\n",
    "hazard_fn, = glob.glob(str(fiat_path/\"hazard\")+\"/*.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"risk\" in Path(hazard_fn).name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(hazard_fn).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test github acccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"/home/wotromp/InterTwin/workflow_refactor/fa_database/Humber_new/input/events/test_event_rucio/meteo.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(ds.encoding[\"source\"]).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"latitude\" in ds.coords:\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.to_datetime(\"2013-12-04 00:00:00\")-pd.DateOffset(years=1)).strftime(\"%Y:%m:%d %H:%M:%S\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DT-flood",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
